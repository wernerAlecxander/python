# -----------------------------MEMORY MANAGEMENT (START)
# cleam memory everytime that a function become unnecessary:

import gc

def killer_func():
    result = []
    x = large_dataset_1()
    result.append(process_function(x))
    del x
    gc.collect()
    
    y = large_dataset_2()
    result.append(process_function(y))
    del y
    gc.collect()
    
    z = large_dataset_3()
    result.append(process_function(z))
    del z
    gc.collect()
    
    return result

# slice the function in small chunks to improve the memory management:

def process_large_dataset_1():
    x = large_dataset_1()
    result = process_function(x)
    return result

def process_large_dataset_2():
    y = large_dataset_2()
    result = process_function(y)
    return result

def process_large_dataset_3():
    z = large_dataset_3()
    result = process_function(z)
    return result
def killer_func():
    result = []
    result.append(process_large_dataset_1())
    result.append(process_large_dataset_2())
    result.append(process_large_dataset_3())
    return result

# process the data in smaller chunks:

def process_file_in_chunks(file_path, chunk_size=1024):
    with open(file_path, 'r') as file:
        while chunk := file.read(chunk_size):
            process_function(chunk)

# Use generators to process items one at a time instead of loading everything into memory:

def large_dataset_generator():
    for i in range(large_dataset_size):
        yield fetch_data(i)

def killer_func():
    result = []
    for data in large_dataset_generator():
        result.append(process_function(data))
    return result

#https://medium.com/@gabrielpelizzaro/how-to-safely-clean-memory-in-python-a-practical-guide-8e4dfa76d375
----------------------------------------------------------------
# import garbage collection module
import gc

# Create a list with a cyclic reference
my_list = []
my_list.append(my_list)

# Delete the list
del my_list

# Manually trigger garbage collection
collected = gc.collect()

# Verify memory release
print(f"Garbage collector collected {collected} objects.")

---------------

import gc
import tracemalloc

# Create a large list
data = [i for i in range(1000000)]

# Measure memory usage before deletion
tracemalloc.start()
snapshot1 = tracemalloc.take_snapshot()

# Delete the list explicitly
del data

# Force garbage collection to ensure memory release
gc.collect()

# Measure memory usage after deletion
snapshot2 = tracemalloc.take_snapshot()
stats = snapshot2.compare_to(snapshot1, 'lineno')
print(f"Memory released by deleting large list: {stats[0].size_diff / 10**6:.2f} MB")

-----------------

import gc
import tracemalloc

# Create a large dictionary
data_dict = {i: str(i) for i in range(10**6)}

# Measure memory usage before clearing
tracemalloc.start()
snapshot1 = tracemalloc.take_snapshot()

# Clear the dictionary explicitly
data_dict.clear()

# Force garbage collection to release memory
gc.collect()

# Measure memory usage after clearing
snapshot2 = tracemalloc.take_snapshot()
stats = snapshot2.compare_to(snapshot1, 'lineno')
print(f"Memory released by clearing dictionary: {stats[0].size_diff / 10**6:.2f} MB")

# https://www.geeksforgeeks.org/python/releasing-memory-in-python/

---------------------------------------------------------------------------

import ctypes

# Assuming you have a pointer to a C-allocated memory (STUDY THIS SUBJECT)
ctypes.cast(pointer, ctypes.POINTER(ctypes.c_char)).contents = None

-----------------

import tracemalloc

tracemalloc.start()

# ... run your application ...

snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

print("[ Top 10 ]")
for stat in top_stats[:10]:
    print(stat)

---------------------------

import tracemalloc

# Store 25 frames
tracemalloc.start(25)

# ... run your application ...

snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('traceback')

# pick the biggest memory block
stat = top_stats[0]
print("%s memory blocks: %.1f KiB" % (stat.count, stat.size / 1024))
for line in stat.traceback.format():
    print(line)

------------------------

import linecache
import os
import tracemalloc

def display_top(snapshot, key_type='lineno', limit=10):
    snapshot = snapshot.filter_traces((
        tracemalloc.Filter(False, "<frozen importlib._bootstrap>"),
        tracemalloc.Filter(False, "<unknown>"),
    ))
    top_stats = snapshot.statistics(key_type)

    print("Top %s lines" % limit)
    for index, stat in enumerate(top_stats[:limit], 1):
        frame = stat.traceback[0]
        print("#%s: %s:%s: %.1f KiB"
              % (index, frame.filename, frame.lineno, stat.size / 1024))
        line = linecache.getline(frame.filename, frame.lineno).strip()
        if line:
            print('    %s' % line)

    other = top_stats[limit:]
    if other:
        size = sum(stat.size for stat in other)
        print("%s other: %.1f KiB" % (len(other), size / 1024))
    total = sum(stat.size for stat in top_stats)
    print("Total allocated size: %.1f KiB" % (total / 1024))

tracemalloc.start()

# ... run your application ...

snapshot = tracemalloc.take_snapshot()
display_top(snapshot)

-----------------

import tracemalloc

tracemalloc.start()

# Example code: compute a sum with a large temporary list
large_sum = sum(list(range(100000)))

first_size, first_peak = tracemalloc.get_traced_memory()

tracemalloc.reset_peak()

# Example code: compute a sum with a small temporary list
small_sum = sum(list(range(1000)))

second_size, second_peak = tracemalloc.get_traced_memory()

print(f"{first_size=}, {first_peak=}")
print(f"{second_size=}, {second_peak=}")

------------------

# https://docs.python.org/3/library/tracemalloc.html (IMPORTANT)

-----------------------------------------------------------------------------------------------

gc.enable()
# Enable automatic garbage collection.

gc.disable()
# Disable automatic garbage collection.

gc.isenabled()
# Return True if automatic collection is enabled.

gc.collect(generation=2)
# The sum of collected objects and uncollectable objects is returned.

gc.set_debug(flags)

gc.get_debug()

gc.get_objects(generation=None)

gc.get_stats()

gc.set_threshold(threshold0[, threshold1[, threshold2]])

gc.get_count()
# return the current collection counts as a tuple of (count0, count1, count2).

gc.get_count()

gc.get_referents(*objs)

gc.is_tracked(obj)
# Returns True if the object is currently tracked by the garbage collector, False otherwise.
-----------------------------
gc.is_tracked(0)

gc.is_tracked("a")

gc.is_tracked([])

gc.is_tracked({})

gc.is_tracked({"a": 1})

gc.is_tracked({"a": []})
--------------------------------

gc.freeze()
# Freeze all the objects tracked by the garbage collector; move them to a permanent generation and ignore them in all the future collections.

gc.unfreeze()
# Unfreeze the objects in the permanent generation, put them back into the oldest generation.

gc.get_freeze_count()
# Return the number of objects in the permanent generation.

gc.garbage
# A list of objects which the collector found to be unreachable but could not be freed (uncollectable objects).

gc.callbacks
# A list of callbacks that will be invoked by the garbage collector before and after collection.

gc.DEBUG_STATS
# Print statistics during collection. This information can be useful when tuning the collection frequency.

gc.DEBUG_COLLECTABLE
# Print information on collectable objects found.

gc.DEBUG_UNCOLLECTABLE
# Print information of uncollectable objects found (objects which are not reachable but cannot be freed by the collector).

gc.DEBUG_SAVEALL
# When set, all unreachable objects found will be appended to garbage rather than being freed.

gc.DEBUG_LEAK
# The debugging flags necessary for the collector to print information about a leaking program (equal to DEBUG_COLLECTABLE | DEBUG_UNCOLLECTABLE | DEBUG_SAVEALL).

# https://docs.python.org/3/library/gc.html#gc.get_referrers
------------------------------------------------------------------------------------
